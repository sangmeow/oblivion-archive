2025-08-09 19:38:38,026 - INFO - GPU 사용 가능: NVIDIA GeForce RTX 3060 Ti
2025-08-09 19:38:38,027 - INFO - 문서 폴더에서 데이터 로딩 중: ../documents
2025-08-09 19:38:38,028 - INFO - 처리 완료: gpt.md (길이: 1824 문자)
2025-08-09 19:38:38,028 - INFO - 처리 완료: sickdog.txt (길이: 3187 문자)
2025-08-09 19:38:38,029 - INFO - 처리 완료: sickdog_bio.md (길이: 1732 문자)
2025-08-09 19:38:38,029 - INFO - 총 3개 파일 처리 완료
2025-08-09 19:38:38,034 - INFO - 모델 로딩 중: ../../models/gpt-oss-20b
2025-08-09 19:38:38,787 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-08-09 19:39:36,306 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu and disk.
2025-08-09 19:39:36,342 - INFO - 모델 로딩 완료
2025-08-09 19:39:36,345 - INFO - LoRA 설정 중...
2025-08-09 19:39:36,530 - INFO - LoRA 설정 완료
2025-08-09 19:39:36,534 - INFO - 데이터셋 토크나이징 중...
2025-08-09 19:41:02,434 - WARNING - Parameter 'function'=<function GPTTrainer.tokenize_dataset.<locals>.tokenize_function at 0x0000025BD8798E00> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-08-09 19:41:03,800 - INFO - 토크나이징 완료: 3개 샘플
2025-08-09 19:41:03,800 - INFO - 학습 시작...
2025-08-09 19:41:03,808 - ERROR - 실행 중 오류 발생: TrainingArguments.__init__() got an unexpected keyword argument 'max_length'
2025-08-09 19:41:57,416 - INFO - GPU 사용 가능: NVIDIA GeForce RTX 3060 Ti
2025-08-09 19:41:57,417 - INFO - 문서 폴더에서 데이터 로딩 중: ../documents
2025-08-09 19:41:57,417 - INFO - 처리 완료: gpt.md (길이: 1824 문자)
2025-08-09 19:41:57,418 - INFO - 처리 완료: sickdog.txt (길이: 3187 문자)
2025-08-09 19:41:57,419 - INFO - 처리 완료: sickdog_bio.md (길이: 1732 문자)
2025-08-09 19:41:57,419 - INFO - 총 3개 파일 처리 완료
2025-08-09 19:41:57,421 - INFO - 모델 로딩 중: ../../models/gpt-oss-20b
2025-08-09 19:41:58,168 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-08-09 19:42:54,198 - WARNING - Some parameters are on the meta device because they were offloaded to the cpu and disk.
2025-08-09 19:42:54,207 - INFO - 모델 로딩 완료
2025-08-09 19:42:54,207 - INFO - LoRA 설정 중...
2025-08-09 19:42:54,298 - INFO - LoRA 설정 완료
2025-08-09 19:42:54,298 - INFO - 데이터셋 토크나이징 중...
2025-08-09 19:44:00,315 - WARNING - Parameter 'function'=<function GPTTrainer.tokenize_dataset.<locals>.tokenize_function at 0x00000255EA3B8C20> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-08-09 19:44:01,412 - INFO - 토크나이징 완료: 3개 샘플
2025-08-09 19:44:01,413 - INFO - 학습 시작...
2025-08-09 19:44:04,557 - ERROR - 실행 중 오류 발생: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2025-08-09 19:47:09,086 - INFO - GPU 사용 가능: NVIDIA GeForce RTX 3060 Ti
2025-08-09 19:47:09,086 - INFO - 문서 폴더에서 데이터 로딩 중: ../documents
2025-08-09 19:47:09,087 - INFO - 처리 완료: gpt.md (길이: 1824 문자)
2025-08-09 19:47:09,087 - INFO - 처리 완료: sickdog.txt (길이: 3187 문자)
2025-08-09 19:47:09,089 - INFO - 처리 완료: sickdog_bio.md (길이: 1732 문자)
2025-08-09 19:47:09,089 - INFO - 총 3개 파일 처리 완료
2025-08-09 19:47:09,091 - INFO - 모델 로딩 중: ../../models/gpt-oss-20b
2025-08-09 19:48:50,550 - ERROR - 모델 로딩 실패: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 22.05 GiB is allocated by PyTorch, and 88.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-08-09 19:48:50,566 - INFO - 대안 방법으로 재시도...
2025-08-09 19:48:52,937 - ERROR - 대안 방법도 실패: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 90.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-08-09 19:48:52,937 - ERROR - 실행 중 오류 발생: CUDA out of memory. Tried to allocate 508.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Of the allocated memory 22.21 GiB is allocated by PyTorch, and 90.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
